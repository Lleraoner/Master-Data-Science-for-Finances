"0","##Esfericidad de bartlet"
"0","library(psych)"
"0","#que todas las varianzas de una poblacio son iguales H0, buscamos rechazarla, este no es robusto ante incrementos del tama?o muestral"
"0","cortest.bartlett(correlaciondata_pca, n = nrow(primer_150)) ##La prueba de esfericidad de Bartlett contrasta la hipÃ³tesis nula de que la matriz de correlaciones es una matriz identidad, en cuyo caso no existirÃ�an correlaciones significativas entre las variables y el modelo factorial no serÃ�a pertinente.## Si Sig. (p-valor) < 0.05 aceptamos H0 (hipÃ³tesis nula) > se puede aplicar el anÃ¡lisis."
"1","$`chisq`
"
"1","[1]"
"1"," 117.9943"
"1","
"
"1","
"
"1","$p.value
"
"1","[1]"
"1"," 4.632803e-18"
"1","
"
"1","
"
"1","$df
"
"1","[1]"
"1"," 15"
"1","
"
"1","
"
"0","#la matriz de covarianzas lo que hace es ver como influye en el total una variable, si tiene un coeficiente alto necesariamente ser? importante en el an?lisis."
"0","cov(primer_150_sca)"
"1","                    "
"1"," primer_150.IMPRESION"
"1"," Alojamiento_general"
"1"," Restaurante_general"
"1"," Entorno_general"
"1","    ingresos"
"1"," primer_150.EDAD"
"1","
primer_150.IMPRESION"
"1","           1.00000000"
"1","          0.21123341"
"1","          0.29355748"
"1","       0.3963611"
"1"," -0.06792637"
"1","     -0.07770759"
"1","
Alojamiento_general "
"1","           0.21123341"
"1","          1.00000000"
"1","          0.41258025"
"1","       0.2447454"
"1","  0.05267344"
"1","      0.14401288"
"1","
Restaurante_general "
"1","           0.29355748"
"1","          0.41258025"
"1","          1.00000000"
"1","       0.5306740"
"1"," -0.13141137"
"1","      0.04432412"
"1","
Entorno_general     "
"1","           0.39636109"
"1","          0.24474538"
"1","          0.53067404"
"1","       1.0000000"
"1"," -0.12714538"
"1","      0.10030925"
"1","
ingresos            "
"1","          -0.06792637"
"1","          0.05267344"
"1","         -0.13141137"
"1","      -0.1271454"
"1","  1.00000000"
"1","      0.10143831"
"1","
primer_150.EDAD     "
"1","          -0.07770759"
"1","          0.14401288"
"1","          0.04432412"
"1","       0.1003092"
"1","  0.10143831"
"1","      1.00000000"
"1","
"
"0","det(correlaciondata_pca)"
"1","[1]"
"1"," 0.4460792"
"1","
"
"0","##KMO es una prueba estadistica la cual es una MSA, medida de adecuacion muestral, definicion(compara los valores de las correlaciones entre las variables y sus correlaciones parciales si el indice Kmo esta proximo a 1 el ACP se puede hacer si es proximo a 0, el ACP no serÃ¡ relevante)"
"0","KMO(correlaciondata_pca)## definicion de kmo, como se puede observar en el kmo todos con mayores de 0.7, por tanto "
"1","Kaiser-Meyer-Olkin factor adequacy"
"1","
Call: "
"1","KMO(r = correlaciondata_pca)
"
"1","Overall MSA = "
"1"," "
"1","0.63"
"1","
MSA for each item = 
"
"1","primer_150.IMPRESION "
"1"," Alojamiento_general "
"1"," Restaurante_general "
"1","     Entorno_general "
"1","            ingresos "
"1","     primer_150.EDAD "
"1","
"
"1","                0.69 "
"1","                0.65 "
"1","                0.63 "
"1","                0.63 "
"1","                0.57 "
"1","                0.42 "
"1","
"
"0","##AnÃ¡lisis de componentes principales. Cuanto mÃ¡s cerca de 1 tenga el valor obtenido del test KMO, implica que la relaciÃ³n entres las variables es alta. Si KMO â¥ 0.9"
"0","library(missMDA)"
"0","acp <- PCA(primer_150_unido, scale.unit = T) ## esta nos arroja resultados mas precisos. Nos retorna la dv estandar de cada uno de los componentes principales , los cuales coinciden con los autovalores de los componentes principales, y nos retorna el conjunto de componentes principales"
