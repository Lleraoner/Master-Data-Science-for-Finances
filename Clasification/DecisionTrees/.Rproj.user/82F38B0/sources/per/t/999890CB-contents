---
title: "Arboles"
author: "Luis Llera García"
date: "4 de febrero de 2019"
output: html_document
---

```{r setup, include=FALSE}
library(openxlsx)
library(readxl)
ruta <- 'BDexamen2.xlsx'
datos<- read_xlsx(ruta, sheet='bd', col_names = TRUE)
# Exploration variables
str(datos)

summary(datos)

# Explore NA values
ExploreNA <- function(datos) {
  TrueNA <- is.na.data.frame(datos)
  SumNA <- colSums(TrueNA)
  PorcentNA <- colSums(TrueNA) / nrow(datos)*100
  VariableNA <- data.frame(SumNA, PorcentNA)
  
  return(VariableNA)
} 
ExploreNA(datos)


datos <- na.omit(datos)
# Create dummy variables (function)
library(dplyr)
library(tidyr)

#Conversión a factor de las variables que nos interesen

#Para nuestra variable dependiente
datos$REGTEN <- as.factor(datos$REGTEN)

#Para el resto de las variables
datos$TAMAMU <- as.factor(datos$TAMAMU)
datos$DENSIDAD <- as.factor(datos$DENSIDAD)
datos$SEXO <- as.factor(datos$SEXO)
datos$ESTUD <- as.factor(datos$ESTUD)
datos$LAB <- as.factor(datos$LAB)
datos$cat2 <- as.factor(datos$cat2)
datos$cat3 <- as.factor(datos$cat3)

datos$EDAD<- as.numeric(datos$EDAD)

#No factorizarmos las variables EDAD, SEXO, SUPERF, y IMPEXAC

str(datos)

# Divide train and test sample
set.seed(123)
train <- sample(nrow(datos), 0.7*nrow(datos))
datos_train <- datos[train,]
datos_test <- datos[-train,]

# Exploratory Analysis (dependient variable)
table(datos_train$cat2)
#Para observar como est? distribuida la variable categ?rica
plot(as.factor(datos$cat2))


par(mfrow = c(1,2)) 
plot(as.factor(datos_train$cat2), main = "Muestra de training") 
plot(as.factor(datos_test$cat2), main = "Muestra de test")

datos_train$cat3 <- NULL
datos_test$ca3 <- NULL
```



```{r, }
########################################ARBOLES DE DECISION#####################################################################
library(ROCR)
library(rpart)
library(rpart.plot)
set.seed(123)
arbol <- rpart(cat2 ~ ., 
               data=datos_train, 
               method="class",
               parms=list(split="information"))
print(arbol)

arbol.pred1 <- predict(arbol, datos_test, type="class")

tabla.clasif.arbol1 <- table(datos_test$cat2, arbol.pred1,
                             dnn=c("Actual", "Predicted"))

tabla.clasif.arbol1

accuracy_primer_arbol <- 100 * sum(diag(tabla.clasif.arbol1))/sum(tabla.clasif.arbol1)
accuracy_primer_arbol
```

```{r,include=TRUE}
tabla.clasif.arbol1
accuracy_primer_arbol
# Resumen de la importancia de las variables en el modelo (arbol sin podar)
arbol$variable.importance
```


```{r,include=TRUE}
# Visualizar el grafico de los parametros de complejidad
plotcp(arbol)
rpart.plot(arbol, box.palette = "GnBu", branch.lty = 3, 
           shadow.col = "gray", 
           nn = TRUE, main = "Árbol de clasificación para Pobreza")
#rEPRESENTACIÓN CURVA ROC ARBOL NORMAL
```

```{r, include=TRUE,echo=TRUE}
prediccion_arbol <- predict(arbol, datos_test, type="prob")[,2] 
pred_arbol = prediction(prediccion_arbol, datos_test$cat2) 

AUC3 <- performance(pred_arbol, "auc")

perf3 <- performance(pred_arbol, "tpr", "fpr")

plot(perf3, colorize = TRUE)

abline(a = 0, b = 1)

text(0.4, 0.6, paste(AUC3@y.name, "\n", round(unlist(AUC3@y.values), 5)), cex = 0.7)
```
```{r,include=TRUE,echo=TRUE}
#############ARBOL PODADO

# Determinar el parametro de complejidad relativo error minimo
arbol$cptable[which.min(arbol$cptable[,"xerror"]),"CP"]

# Visualizar la tabla de los parametros de complejidad (comprobacion de eleccion)
printcp(arbol) 

# Para la poda necesitar????amos el menos xerror el cual es 0.31452

arbol_podado = prune(arbol, cp = 0.23060)

# Cargamos libreria para visualizar el modelo del arbol por pureza
library(rpart.plot)

rpart.plot(arbol_podado, box.palette = "GnBu", branch.lty = 3, 
           shadow.col = "gray", 
           nn = TRUE, main = "Árbol de clasificación para Pobreza")
```
```{r,include =TRUE,echo=TRUE}
#Otra forma de visualizarlo
 prp(arbol_podado, type = 2, extra = 104, fallen.leaves = TRUE, main = "Decision Tree")


 # Prediccion con la muestra de validacion
 arbol_prediccion <- predict(arbol_podado, datos_test, type = "class")
 
 #  Se trabaja sobre el arbol podado
 arbol_resultado_total <- table(datos_test$cat2, arbol_prediccion,
                                dnn = c("Actual", "Predicted"))

 # Tabla de doble entrada
 arbol_resultado_total
 accuracy_arbolpodado <- 100 * sum(diag(arbol_resultado_total))/sum(arbol_resultado_total)
 accuracy_arbolpodado
```


```{r}
 ###########################################################
 #########Prueba de arbol 2, pero esta vez mas sencillo ##
 ##########################################################
 
 set.seed(4578)
 train <- sample(nrow(datos), 0.6*nrow(datos)) #Para el train nos quedaremos con el 70% de la sobservaciones
 datos.train<- datos_train# 286 observaciones y 12 variables
 
 #Lo anterior muestra el esquema de nuestro árbol de clasificación. Cada inciso nos indica un nodo y 
 #la regla de clasificación que le corresponde. Siguiendo estos nodos, 
 #podemos llegar a las hojas del árbol, que corresponde a la clasificación de nuestros datos.
 
 datos.test <- datos_test# 191 observaciones y 12 variables
 table(datos.train$cat2)# 210 no están en riesgo de pobreza y 123 que s???? lo están
 table(datos.test$cat2)# 81 no están en riesgo de pobreza y 63 s???? que lo están
 
 library(rpart)
 arbol <- rpart(cat2 ~ ., data=datos.train, method="class",parms=list(split="information"))
 plot(arbol, uniform = TRUE, branch=0.4, compress=FALSE)
 text(arbol, use.n = TRUE, cex = 0.75, all=TRUE)
 print(arbol)
 rpart.plot(arbol, box.palette = "GnBu", branch.lty = 3, 
            shadow.col = "gray", 
            nn = TRUE, main = "Árbol de clasificación para Pobreza")
 ##Lo anterior muestra el esquema de nuestro árbol de clasificación. Cada inciso nos indica un nodo y la regla de clasificación que le corresponde. Siguiendo estos nodos, podemos llegar a las hojas del árbol, que corresponde a la clasificación de nuestros datos.
 #Todo lo anterior resulta mucho más claro si lo visualizamos, as???? que creamos una gráfica usando nuestro modelo con la función  rpart.plot() de rpart.plot.
 
 
 summary(arbol)
 rpart.plot(arbol)
 arbol$cptable #esta es la tabla de complejidad paramétrica en donde tendremos los erroresde validación cruzada, tendremos que ver cuál de ellos es el que 
 #minimiza el error de cross-validation
 plotcp(arbol)
 printcp(arbol)
 plot(arbol)
 text(arbol, use.n = TRUE, cex = 0.75, all=TRUE)
 arbol$cptable[which.min(arbol$cptable[,"xerror"]),"CP"]# el error que minimiza la validación cruzada es cp=0.01
 arbol.podado = prune(arbol, cp = 0.23353)
 rpart.plot(arbol.podado, box.palette = "GnBu", branch.lty = 3, 
            shadow.col = "gray", 
            nn = TRUE, main = "Árbol de clasificación para Pobreza")
 

 
 #En estos gráficos, cada uno de los rectángulos representa un nodo de nuestro árbol, con su regla de clasificación.
 #Cada nodo está coloreado de acuerdo a la categor????a mayoritaria entre los datos que agrupa. Esta es la categor????a que ha predicho el modelo para ese grupo.
 #Dentro del rectángulo de cada nodo se nos muestra qué proporción de casos pertenecen a cada categor????a y la proporción del total de datos que han sido
 #agrupados all????. Por ejemplo, el rectángulo en el extremo inferior izquierdo de la gráfica tiene 94% de casos en el tipo 1, y 4% en los tipos 2 y 3, que representan 39% de todos los datos.
 #Estas proporciones nos dan una idea de la precisión de nuestro modelo al hacer predicciones. De este modo, las reglas que conducen al rectángulo que acabamos
 #de mencionar nos dan un 92% de clasificaciones correctas. En contraste, el tercer rectángulo, de izquierda a derecha, de color gris, tuvo sólo 62% de clasificaciones correctas.
 #Además, podemos sentirnos contentos de que dos de las hojas de nuestro árbol de clasificación han logrado un 100% de clasificaciones correctas, para los vinos de tipo 2 y 3.
 #Pero, por supuesto, necesitamos ser más sistemáticos para indagar qué tan bien hace predicciones nuestro modelo.
 #Usamos la función precict() con nuestro set de prueba para generar un vector con los valores predichos por el modelo que hemos entrenado, especificamos el parámetro type = "class".
 
 library(rpart.plot)
 
 prp(arbol.podado, type = 2, extra = 104,fallen.leaves = TRUE, main="Decision Tree")
 arbol.pred <- predict(arbol.podado, datos.test, type="class")
 

 rpart.plot(arbol.podado)
 rpart.plot(arbol.podado, box.palette="GnBu",branch.lty=3, shadow.col="gray", nn=TRUE,main="Árbol de clasificación usando rpart.plot")
 
 
 library(partykit)
 
 plot(as.party(arbol.podado))
 
 #El paequete party proporciona árboles de regresión no paramétrixa para respuestas nominales, ordinales, numéricas,
 #censuradas o multivariantes #El crecmimiento del árbol se basa en reglas estad????sticas de parada, de forma que no se hace necesaria la poda
 
 
 arbol.party1 = ctree(cat2 ~ ., datos.train)
 plot(arbol.party1, main="Árbol de inferencia condicional para los Hogares en riesgo de pobreza")
 ctree.pred <- predict(arbol.party1, datos.test, type="response")

```


